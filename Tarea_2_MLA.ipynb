{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 2: Redes Convolucionales\n",
        "Integrantes:\n",
        "- Kurt Castro\n",
        "- Diego León\n",
        "- Cristián Pizarro"
      ],
      "metadata": {
        "id": "LpEzpwE4VMGC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIFxV-IbFuTG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras import models, layers, optimizers, regularizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import kagglehub\n",
        "# Establecer la semilla para Python\n",
        "random.seed(42)\n",
        "\n",
        "# Establecer la semilla para NumPy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Establecer la semilla para TensorFlow\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activar GPU en \"Entorno de Ejecución\". No lo olviden o estarán horas entrenando!"
      ],
      "metadata": {
        "id": "O1Xm607pP8nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica las GPUs disponibles\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"Se encontró GPU: {gpus}\")\n",
        "else:\n",
        "    print(\"No se encontró GPU. Asegúrate de haber activado el entorno con GPU en Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHQ0K-G1OiTG",
        "outputId": "b8d3f108-1273-48a8-d3ec-b469e6993afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se encontró GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"samuelcortinhas/muffin-vs-chihuahua-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH3_xtJhHyYC",
        "outputId": "060f10c3-d6f1-4154-bd0c-c1d9d49b6a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/samuelcortinhas/muffin-vs-chihuahua-image-classification?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 474M/474M [00:21<00:00, 22.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/root/.cache/kagglehub/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification/versions/2\""
      ],
      "metadata": {
        "id": "lVi6MTlxILEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image generator\n",
        "data_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    vertical_flip=True,\n",
        "                                    horizontal_flip=True)\n",
        "\n",
        "# train y test\n",
        "train_dir = f'{base_path}/train'\n",
        "test_dir = f'{base_path}/test'\n",
        "\n",
        "batch_size = 16\n",
        "num_classes = 2\n",
        "\n",
        "\n",
        "# generators\n",
        "image_size = (150, 150)\n",
        "input_shape = (150, 150, 3)\n",
        "\n",
        "# Cargar datos directamente\n",
        "X_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "X_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Convertir a tensores numpy si es necesario\n",
        "X_train, y_train = [], []\n",
        "for images, labels in X_train_ds:\n",
        "    X_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())\n",
        "\n",
        "X_test, y_test = [], []\n",
        "for images, labels in X_test_ds:\n",
        "    X_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())\n",
        "\n",
        "# Combinar los datos en arreglos numpy\n",
        "X_train = np.concatenate(X_train)\n",
        "y_train = np.concatenate(y_train).ravel()\n",
        "X_test = np.concatenate(X_test)\n",
        "y_test = np.concatenate(y_test).ravel()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLFyPi_0GJYl",
        "outputId": "2dbb241a-78c2-4858-ec01-4f64eee3f367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4733 files belonging to 2 classes.\n",
            "Found 1184 files belonging to 2 classes.\n",
            "X_train shape: (4733, 150, 150, 3), y_train shape: (4733,)\n",
            "X_test shape: (1184, 150, 150, 3), y_test shape: (1184,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "npkV0YGUR2Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiones originales de las imágenes\n",
        "num_samples, height, width, channels = X_train.shape\n",
        "\n",
        "# Aplanar las imágenes\n",
        "X_train_flattened = X_train.reshape(num_samples, height * width * channels)\n",
        "\n",
        "# Si tienes un conjunto de prueba\n",
        "X_test_flattened = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2] * X_test.shape[3])"
      ],
      "metadata": {
        "id": "Xc4t-lAASqSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 128\n",
        "model_mlp = Sequential([\n",
        "    Dense(hidden_units, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Una sola salida para clasificación binaria\n",
        "])\n",
        "\n",
        "model_mlp.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=1e-2),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#traint the parameters\n",
        "history = model_mlp.fit(X_train_flattened, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size)\n",
        "\n",
        "#evalute the accuracy\n",
        "train_acc=model_mlp.evaluate(X_train_flattened, y_train, batch_size=batch_size)[1]\n",
        "test_acc=model_mlp.evaluate(X_test_flattened, y_test, batch_size=batch_size)[1]\n",
        "print(f'Training accuracy: {train_acc:.2f}')\n",
        "print(f'Test accuracy: {test_acc:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AjDLNz7SJvr",
        "outputId": "9d821c33-a017-4071-9459-b47f14e808a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5811 - loss: 11867.1836\n",
            "Epoch 2/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.8397\n",
            "Epoch 3/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7098 - loss: 0.6570\n",
            "Epoch 4/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7124 - loss: 0.6338\n",
            "Epoch 5/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6993 - loss: 0.6390\n",
            "Epoch 6/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.6515\n",
            "Epoch 7/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7025 - loss: 0.6239\n",
            "Epoch 8/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7047 - loss: 0.6282\n",
            "Epoch 9/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6474 - loss: 0.6844\n",
            "Epoch 10/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5407 - loss: 0.6897\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5733 - loss: 0.6732\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6014 - loss: 0.6583\n",
            "Training accuracy: 0.59\n",
            "Test accuracy: 0.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red convolucional"
      ],
      "metadata": {
        "id": "ijNTnfclR0C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation='sigmoid')  # Una sola salida para clasificación binaria\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnYVb2VeJnYq",
        "outputId": "7270e297-2865-4660-c2e3-c0662504793a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer = keras.optimizers.Adadelta(),\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ugKXHkFIKI09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTWAIWZrLTEe",
        "outputId": "a45d90bb-beec-4680-a576-85c122836cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4733, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isexr46LLVWC",
        "outputId": "8d3a057a-dc4c-4e9a-e0c5-4ebf66893cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4733,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_cnn.fit(\n",
        "X_train, y_train,\n",
        "batch_size=batch_size,\n",
        "epochs=10,\n",
        "verbose = 1,\n",
        "validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "#evalute the accuracy\n",
        "train_acc=model_cnn.evaluate(X_train, y_train, batch_size=batch_size)[1]\n",
        "test_acc=model_cnn.evaluate(X_test, y_test, batch_size=batch_size)[1]\n",
        "print(f'Training accuracy: {train_acc:.2f}')\n",
        "print(f'Test accuracy: {test_acc:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_ljY5svKNCo",
        "outputId": "3b57bc10-b8be-4a0f-dcf5-64a18fb66c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.6852 - loss: 0.0000e+00 - val_accuracy: 0.7508 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.7098 - loss: 0.0000e+00 - val_accuracy: 0.7610 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7145 - loss: 0.0000e+00 - val_accuracy: 0.7644 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7230 - loss: 0.0000e+00 - val_accuracy: 0.7677 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7318 - loss: 0.0000e+00 - val_accuracy: 0.7753 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7427 - loss: 0.0000e+00 - val_accuracy: 0.7821 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7528 - loss: 0.0000e+00 - val_accuracy: 0.7863 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7572 - loss: 0.0000e+00 - val_accuracy: 0.7914 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7681 - loss: 0.0000e+00 - val_accuracy: 0.7981 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7767 - loss: 0.0000e+00 - val_accuracy: 0.8074 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7892 - loss: 0.0000e+00\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.0000e+00\n",
            "Training accuracy: 0.80\n",
            "Test accuracy: 0.81\n"
          ]
        }
      ]
    }
  ]
}